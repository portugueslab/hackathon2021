{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Making sense of your imaging data\n",
    "\n",
    "### PortuguesLab Hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Making sense of your imaging data\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "1. (very) Brief introduction to xarray\n",
    "2. Filtering out your non-responsive ROIs\n",
    "3. Clustering your responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's start with some basic imports and the sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import flammkuchen as fl\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Import data\n",
    "dataset = fl.load('/home/otprat/Desktop/hackathon2021/sample_dataset')\n",
    "\n",
    "#Some hardcoded necessary variables that I was too lazy to add in the dictionary\n",
    "n_blocks = 30\n",
    "dt = 0.25 \n",
    "\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "traces = dataset['traces']\n",
    "stim_arr = dataset['stim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "traces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(stim_arr[0, :], stim_arr[1, :])\n",
    "plt.xlabel('Time [s.]')\n",
    "plt.ylabel('Velocity [mm/s.]')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. (very) Brief introduction to xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[Xarray](http://xarray.pydata.org/en/stable/index.html) is a Python package tailored to those working with multidimensional arrays. \n",
    "\n",
    "Built on top of NumPy, it introduces labels in the form of dimensions and coordinates. Also includes a large library of domain-agnostic functions for analytics and visualization with these data structures.\n",
    "\n",
    "Install with:\n",
    "\n",
    "`$ pip install xarray`\n",
    "\n",
    "or\n",
    "\n",
    "`$ conda install -c conda-forge xarray dask netCDF4 bottleneck`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When creating an `DataArray` object, besides the data it will contain, we will also need to specify the dimensions and coordinates of such array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Creating an xarray object with our data\n",
    "traces_xr = xr.DataArray(\n",
    "    data=traces,                               #Adding the data\n",
    "    dims=['roi', 'block', 't'],                #Defining name of the dimensions\n",
    "    coords={                                   #Defining values at which each dimension wase valuated\n",
    "        'roi':np.arange(traces.shape[0]), \n",
    "        'block':np.arange(n_blocks),\n",
    "        't':np.arange(traces.shape[2])*dt\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "traces_xr.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Similarly as with `pandas`, we can index data within a `DataArray` both positionally and by its labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "resp_sample = traces_xr[100, 15, :10] #Index-based indexing\n",
    "resp_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "resp_sample = traces_xr.loc[100, 15, :10] #Label-based indexing\n",
    "resp_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As `xarray` is built on top of `numpy` arrays, most of the basic functions will also work on our data arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mean_resps = np.nanmean(traces_xr, 1)\n",
    "mean_resps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For other packages that may not support such `xarray` objects, data can always be easily retrieved in a `numpy` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "type(traces_xr.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2. Filtering out your non-responsive ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One may expect that imaged ROIs responding to the specific shown stimulus, will do so in a consistent manner across repetitions. Therefore, we could try to assess the reliability of our responses by measuring how similar the trace of a given neuron is across stimulation blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def cross_correlation(traces):\n",
    "    \"\"\" Function calculating ROI reliability, defined as the average correlation of responses across trials.\n",
    "    :param traces: input traces.\n",
    "    :return: reliability values for all ROIs.\n",
    "    \"\"\"\n",
    "    \n",
    "    reliability = np.zeros(traces.shape[0])\n",
    "    \n",
    "    for roi in range(len(reliability)):\n",
    "        trace = traces[roi, :, :]\n",
    "        corr = np.corrcoef(trace)\n",
    "        np.fill_diagonal(corr, np.nan)\n",
    "        reliability[roi] = np.nanmean(corr)\n",
    "\n",
    "    return reliability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate cross correlation between traces and set a threshold\n",
    "reliability = cross_correlation(traces_xr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next, we need to decide what do we consider a reliable ROI.\n",
    "\n",
    "Here, we will use the [Otsu's method](https://www.youtube.com/watch?v=jUUkMaNuHP8&ab_channel=JianWeiTay) for automatically thresholding our reliabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Import filtering method\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "#Apply to reliability histogram\n",
    "rel_thresh = threshold_otsu(reliability)\n",
    "print('Reliability threshold set at {}'.format(rel_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Visualize\n",
    "plt.figure()\n",
    "plt.hist(reliability, bins=50, density=True);\n",
    "plt.axvline(rel_thresh, c='red', ls='--')\n",
    "\n",
    "plt.xlim([0,1])\n",
    "plt.xlabel('Average correlation between reps')\n",
    "plt.ylabel('Density')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Filter cropped traces \n",
    "filtered_traces_xr = traces_xr[reliability >= rel_thresh]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But Otsu's Method is only one of many options..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from inspect import getmembers, isfunction\n",
    "from skimage import filters\n",
    "\n",
    "thresh_methods = [func for func in getmembers(filters, isfunction) if 'threshold_' in str(func) \n",
    "                  and all(s not in str(func) for s in ['local', 'sauvola', 'niblack', 'multiotsu'])]\n",
    "\n",
    "thr_list = []\n",
    "\n",
    "for method in thresh_methods:\n",
    "    thr_list.append(method[1](reliability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(reliability, bins=50, density=True);\n",
    "for thr in thr_list:\n",
    "    plt.axvline(thr, c='red', ls='--')\n",
    "\n",
    "plt.xlim([0,1])\n",
    "plt.xlabel('Average correlation between reps')\n",
    "plt.ylabel('Density');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It's also important to keep in mind the amount of responses that are available to us when calculating such reliabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n_test_rois = 15\n",
    "test_rois = np.random.choice(np.arange(traces_xr.shape[0]), n_test_rois)\n",
    "\n",
    "rel_evol = np.full((n_test_rois, n_blocks-1), np.nan)\n",
    "\n",
    "for block_idx, block in enumerate(np.arange(2, n_blocks)):\n",
    "    rel_evol[:, block_idx] = cross_correlation(traces_xr[test_rois, :block, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "    \n",
    "for roi in range(n_test_rois):\n",
    "    plt.plot(rel_evol[roi, :])\n",
    "    \n",
    "plt.xlabel('Included blocks')\n",
    "plt.ylabel('ROI reliability') \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Clustering your responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Moving onto the clustering a straightforward method is to cluster the responses based on their PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Calculate mean response per trial\n",
    "roi_meanresps = np.nanmean(filtered_traces_xr, 1)\n",
    " \n",
    "#Normalize to mean response before stimulus\n",
    "for roi in range(roi_meanresps.shape[0]):\n",
    "    roi_meanresps[roi, :] = roi_meanresps[roi, :] - np.nanmean(roi_meanresps[roi, :int(5/dt)] )  #5s based on our stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, it would be good to determine how many PCs should we use to describe our responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Perform PCA\n",
    "pca = PCA(n_components=25) #Start by looking at the firts 25 PCs.\n",
    "pca.fit(roi_meanresps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Plot the cumulative explained variance by the main PCs.\n",
    "x=np.arange(0,25,1)\n",
    "expl_var=np.cumsum(pca.explained_variance_ratio_) #This attribute calculates the explained variance by each PC.\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(x, expl_var)\n",
    "plt.xlabel('PCs')\n",
    "plt.ylabel('Explained variance')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will next use the PCs of each response to cluster them using a KMeans method. To do so, we first must decide into how many clusters we want to separate our ROIs. A simple heuristic way to define that number, is to make an **elbow plot**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Define number of principal components based on the explained variance per PC above\n",
    "n_components = 10\n",
    "\n",
    "pca=PCA(n_components=n_components)\n",
    "roi_meanresps_pca=pca.fit_transform(roi_meanresps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Make elbow plot to choose optimal size of clusters\n",
    "distorsions = []\n",
    "\n",
    "for k in range(1, 25):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(roi_meanresps_pca) #Computes the clustering\n",
    "    distorsions.append(kmeans.inertia_) #Appends the inertia attirbute of the fit: Sum of squared distances of samples to their closest cluster center.\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1,25), distorsions)\n",
    "\n",
    "plt.xlabel('# of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And we cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Select number of clusters and clusterize\n",
    "n_clusters = 5\n",
    "\n",
    "kmeans_traces_pca = KMeans(n_clusters=n_clusters, random_state=0).fit_predict(roi_meanresps_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Defining a color palette because plots should be pretty\n",
    "clust_colors =[\"#9bcc40\",\n",
    "\"#ce5bd9\",\n",
    "\"#61cd75\",\n",
    "\"#e55391\",\n",
    "\"#d0a839\",\n",
    "\"#8c7fe3\",\n",
    "\"#e3633f\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(Create your own color palettes in [iWantHue](http://medialab.github.io/iwanthue/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Plot\n",
    "cluster_fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "gs = gridspec.GridSpec(8,22)\n",
    "gs.update(wspace=0.25, hspace=0)\n",
    "ax1 = plt.subplot(gs[:1, 2:12])\n",
    "ax2 = plt.subplot(gs[:1, 12:])\n",
    "ax3 = plt.subplot(gs[1:, 2:12])\n",
    "ax4 = plt.subplot(gs[1:, 12:], sharex=ax2)\n",
    "ax5 = plt.subplot(gs[3:6, 0:1])\n",
    "\n",
    "ax1.plot(stim_arr[0, :], stim_arr[1, :], c='black')\n",
    "ax1.set_xlim(np.min(stim_arr[0, :]),np.max(stim_arr[0, :]))\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.plot(stim_arr[0, :], stim_arr[1, :], c='black')\n",
    "ax2.axis('off')\n",
    "\n",
    "heatmap = ax3.imshow(roi_meanresps[np.argsort(kmeans_traces_pca),:], aspect='auto', cmap='RdBu_r', vmin=-2.5, vmax=2.5)\n",
    "unique, counts = np.unique(kmeans_traces_pca, return_counts=True)\n",
    "yticks=[]\n",
    "tick = 0\n",
    "\n",
    "for cluster, roi_num in zip(unique, counts):\n",
    "    yticks.append(tick)\n",
    "    tick += counts[cluster]\n",
    "    \n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks(yticks)\n",
    "ax3.set_yticklabels(unique+1)\n",
    "for tick in yticks:\n",
    "    ax3.axhline(tick, ls=':', color='black')\n",
    "ax3.set_ylim([roi_meanresps.shape[0], 0])\n",
    "    \n",
    "for tick, col in zip(ax3.yaxis.get_major_ticks(), clust_colors):\n",
    "    tick.label1.set_color(col)\n",
    "\n",
    "cluster, cells = np.unique(kmeans_traces_pca, return_counts=True)\n",
    "cluster_roi_count = dict(zip(cluster, cells))    \n",
    "\n",
    "for cluster, color in zip(np.unique(kmeans_traces_pca), clust_colors):\n",
    "    ax4.plot(stim_arr[0, :], (roi_meanresps[kmeans_traces_pca==cluster,:].mean(0))-cluster*5, c=color, label=cluster)\n",
    "ax4.set_xticks([])\n",
    "ax4.set_yticks([])\n",
    "\n",
    "sns.despine(left=True)\n",
    "cluster_fig.suptitle('Clustered responses by {} main PCs'.format(n_components))\n",
    "\n",
    "plt.colorbar(heatmap, cax=ax5)\n",
    "ax5.set_yticks([])\n",
    "ax5.set_xticks([])\n",
    "ax5.set_ylabel('Fluorescence (norm.)')\n",
    "ax5.yaxis.set_label_position('left')\n",
    "ax5.yaxis.tick_left()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Pick a random subset of ROis\n",
    "rand_rois = np.random.choice(roi_meanresps_pca.shape[0], size=50, replace=False)\n",
    "\n",
    "#Clustering\n",
    "linked = linkage(roi_meanresps_pca[rand_rois, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Plot\n",
    "plt.figure()\n",
    "dendrogram(linked);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Interactive plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from ipywidgets.widgets import IntSlider, Dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cluster_rois(cluster, roi):\n",
    "    \n",
    "    roi_idx = np.nonzero(kmeans_traces_pca==cluster)[0][roi]\n",
    "        \n",
    "    ex_roi_fig = plt.figure()\n",
    "    gs = gridspec.GridSpec(10, 10)\n",
    "    gs.update(wspace=0.25, hspace=0)\n",
    "    ax1 = plt.subplot(gs[:2, :])\n",
    "    ax2 = plt.subplot(gs[2:, :], sharex=ax1)\n",
    "\n",
    "    ax1.plot(stim_arr[0,:], stim_arr[1, :], c='black')\n",
    "    ax1.set_xlim(np.min(stim_arr[0,:]),np.max(stim_arr[0,:]))\n",
    "    ax1.axis('off')\n",
    "\n",
    "    for block in range(n_blocks):\n",
    "        ax2.plot(filtered_traces_xr.coords['t'], filtered_traces_xr[roi_idx, block, :], c='gray', alpha=.1)\n",
    "\n",
    "    ax2.plot(filtered_traces_xr.coords['t'], np.nanmean(filtered_traces_xr[roi_idx, :, :], 0), c=clust_colors[cluster])\n",
    "\n",
    "    ax2.set_xlabel('Time [s.]')\n",
    "    ax2.set_ylabel('dF/F')\n",
    "    \n",
    "    ax1.set_title('Cluster {}, ROI {}'.format(cluster+1, roi))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "cluster_roi_resps = interact(plot_cluster_rois,\n",
    "                             cluster=Dropdown(options=np.unique(kmeans_traces_pca), \n",
    "                                              description='Cluster'),\n",
    "                             roi=IntSlider(min=0, \n",
    "                                           max=np.nonzero(kmeans_traces_pca==cluster)[0].shape[0]-1, \n",
    "                                           step=1, \n",
    "                                           continuous_update=True))\n",
    "display(cluster_roi_resps)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
